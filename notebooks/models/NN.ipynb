{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from config import Config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset, pre-processing it and tokenizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.pipeline import ItalianTweetsPreprocessingPipeline\n",
    "from preprocessing.tokenization import ItalianTweetsTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Config.TRAINING_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automatically pre-processes the dataset\n",
    "itt = ItalianTweetsTokenizer()\n",
    "dft = itt.tokenize(df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = itt.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(tok.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tk\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(num_words, 32, input_length=Config.SEQUENCE_LENGTH, mask_zero=True))\n",
    "model.add(keras.layers.GRU(32, return_sequences=True, recurrent_dropout=0.4))\n",
    "model.add(keras.layers.GRU(32, recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(keras.layers.GRU(16, recurrent_dropout=0.3))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 50, 32)            466784    \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 50, 32)            6336      \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 50, 32)            6336      \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (None, 16)                2400      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 481,873\n",
      "Trainable params: 481,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dft, df['irony'].to_numpy(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].reshape(1,50).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3181, 50)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   1,  939,  112, ...,    0,    0,    0]],\n",
       "\n",
       "       [[ 635,   42,    1, ...,    0,    0,    0]],\n",
       "\n",
       "       [[   1,   81,    1, ...,    0,    0,    0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[   1,  429, 1834, ...,    0,    0,    0]],\n",
       "\n",
       "       [[   1,    1,    1, ...,    0,    0,    0]],\n",
       "\n",
       "       [[1028,    1, 1230, ...,    0,    0,    0]]], dtype=int32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_reshaped = np.array([x.reshape(1,50) for x in x_train])\n",
    "x_train_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "287/287 [==============================] - 50s 175ms/step - loss: 0.6916 - accuracy: 0.5175 - val_loss: 0.6804 - val_accuracy: 0.5611\n",
      "Epoch 2/10\n",
      "287/287 [==============================] - 46s 159ms/step - loss: 0.4766 - accuracy: 0.7813 - val_loss: 0.7779 - val_accuracy: 0.5423\n",
      "Epoch 3/10\n",
      "287/287 [==============================] - 41s 143ms/step - loss: 0.1681 - accuracy: 0.9368 - val_loss: 0.9620 - val_accuracy: 0.5674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1481c9e50>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=10, epochs=10, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 23ms/step - loss: 0.9950 - accuracy: 0.5804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9949962496757507, 0.5804020166397095]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False,  True,  True,  True,  True, False,\n",
       "        True,  True, False, False,  True,  True, False, False,  True,\n",
       "        True, False, False, False,  True,  True, False, False, False,\n",
       "        True,  True, False,  True,  True,  True, False,  True, False,\n",
       "       False, False,  True, False, False, False,  True,  True,  True,\n",
       "       False, False,  True,  True, False,  True,  True,  True, False,\n",
       "        True,  True, False, False,  True,  True, False, False, False,\n",
       "        True,  True,  True, False, False,  True, False,  True,  True,\n",
       "       False, False, False,  True,  True, False,  True,  True, False,\n",
       "        True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "        True,  True,  True, False,  True, False, False,  True, False,\n",
       "        True, False,  True,  True,  True,  True, False, False,  True,\n",
       "       False,  True,  True, False,  True,  True, False,  True, False,\n",
       "        True, False,  True,  True,  True,  True, False, False,  True,\n",
       "        True,  True, False, False, False,  True,  True, False,  True,\n",
       "       False,  True, False, False,  True, False, False,  True,  True,\n",
       "       False,  True, False,  True, False, False, False,  True, False,\n",
       "        True, False, False,  True,  True,  True,  True,  True, False,\n",
       "       False, False, False,  True,  True,  True,  True, False, False,\n",
       "        True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "        True, False, False, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False,  True,  True,  True, False, False,  True, False,\n",
       "       False, False,  True, False, False, False,  True,  True, False,\n",
       "       False, False,  True, False,  True, False, False,  True,  True,\n",
       "        True, False,  True, False,  True, False,  True, False, False,\n",
       "        True, False,  True,  True, False,  True, False, False,  True,\n",
       "       False, False, False, False, False, False,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True, False, False,  True,\n",
       "       False,  True,  True, False,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "        True, False,  True, False,  True, False,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        True, False,  True, False, False, False,  True, False,  True,\n",
       "        True, False,  True, False,  True, False, False,  True, False,\n",
       "        True, False,  True, False,  True, False, False, False, False,\n",
       "       False, False,  True,  True,  True, False, False,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True, False, False,  True,  True,  True,  True,  True,\n",
       "       False,  True, False,  True,  True,  True, False, False, False,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True, False, False, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "        True,  True, False, False, False,  True,  True, False, False,\n",
       "        True,  True,  True, False,  True, False, False,  True,  True,\n",
       "       False, False, False,  True,  True, False, False,  True, False,\n",
       "        True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "       False, False, False,  True,  True,  True, False, False,  True,\n",
       "        True,  True, False, False,  True, False,  True,  True, False,\n",
       "        True, False, False, False,  True,  True,  True, False, False,\n",
       "        True,  True,  True,  True,  True, False,  True, False, False,\n",
       "        True,  True, False,  True,  True,  True, False, False, False,\n",
       "       False,  True, False, False,  True, False,  True, False,  True,\n",
       "        True,  True, False,  True, False, False,  True,  True, False,\n",
       "        True,  True,  True, False, False, False,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True, False, False, False,\n",
       "       False, False,  True, False,  True,  True, False, False, False,\n",
       "        True,  True,  True,  True,  True, False, False,  True, False,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "       False,  True,  True, False,  True,  True,  True, False,  True,\n",
       "       False,  True, False,  True,  True,  True,  True, False, False,\n",
       "        True,  True, False,  True, False,  True, False, False, False,\n",
       "       False,  True,  True, False, False,  True, False,  True,  True,\n",
       "        True, False, False, False, False,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True, False, False,\n",
       "       False,  True, False, False, False, False,  True,  True,  True,\n",
       "       False,  True, False, False, False, False,  True,  True,  True,\n",
       "       False, False,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False, False, False,  True,\n",
       "        True, False, False, False,  True,  True, False,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "        True,  True, False, False, False,  True, False,  True, False,\n",
       "        True, False,  True,  True,  True, False, False, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True, False, False,\n",
       "        True,  True, False, False, False,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True, False,  True,  True,\n",
       "       False,  True,  True,  True,  True, False,  True, False, False,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "        True, False,  True, False, False,  True,  True, False, False,\n",
       "       False, False, False,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True, False,  True, False, False, False,\n",
       "       False, False, False,  True])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model.predict_classes(x_test).ravel()\n",
    "predicted == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]], dtype=int32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(x_test[0].reshape(1,50)) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
