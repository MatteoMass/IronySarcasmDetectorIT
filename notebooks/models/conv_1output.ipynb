{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50af320-1753-4e5e-a125-f57d0a2f6125",
   "metadata": {},
   "source": [
    "# Grid search target irony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c593ae-ade9-4d10-ac5b-8222928405d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import Config\n",
    "import keras\n",
    "\n",
    "\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee982366-2e04-4458-abfd-2f47959152da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.tokenizationWordVect import tokenize_frame\n",
    "from keras.layers import Conv1D, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daae8ddf-b68e-49ad-aa23-764a09743920",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_1_Dropout = [0.5,0.2]\n",
    "filters = [64, 32]\n",
    "kernel_size = [5,3]\n",
    "activation_conv = ['relu']\n",
    "hidden_layers = [[(32,'relu',0.0),(16,'relu', 0.0)],[(32,'relu',0.1),(16,'relu', 0.1)],  [(24,'relu', 0.0)], [(24,'relu', 0.1)] ]\n",
    "loss = ['mse']\n",
    "epochs = [10, 20]\n",
    "\n",
    "\n",
    "combinations = list(itertools.product(*[filters, kernel_size, activation_conv, level_1_Dropout, hidden_layers, loss, epochs]))\n",
    "combinations\n",
    "\n",
    "\n",
    "\n",
    "validation_performance = []\n",
    "\n",
    "training_data = pd.read_csv(Config.TRAINING_DATASET_PATH)\n",
    "\n",
    "from preprocessing.pipeline import ItalianTweetsPreprocessingPipeline\n",
    "pp = ItalianTweetsPreprocessingPipeline()\n",
    "\n",
    "preprocessed_training_data = pp.apply(training_data)\n",
    "\n",
    "x = preprocessed_training_data['text']\n",
    "y = preprocessed_training_data['irony']\n",
    "\n",
    "x= tokenize_frame(x, \"sostituisciTag\")\n",
    "x = np.asarray(x)\n",
    "\n",
    "tmp = list(zip(x,y))\n",
    "random.shuffle(tmp)\n",
    "x, y = zip(*tmp)\n",
    "\n",
    "\n",
    "validate_size = int(len(x)*VALIDATION_SPLIT)\n",
    "x_train, x_validate = x[:-validate_size], x[-validate_size:]\n",
    "x_train = np.asarray(x_train)\n",
    "x_validate = np.asarray(x_validate)\n",
    "y_train, y_validate = y[:-validate_size], y[-validate_size:]\n",
    "y_train = np.asarray(y_train)\n",
    "y_validate = np.asarray(y_validate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea4449-7f62-4737-b3b0-bacfd5431d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "index = 0\n",
    "print(\"numero di combinazioni da testare \" + str(len(combinations)))\n",
    "for combination in combinations:\n",
    "    print(\"index: \" + str(index) + \" Configurazione: \" + str(combination))\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Conv1D(filters=combination[0], kernel_size=combination[1], activation=combination[2], input_shape=(65,128)))\n",
    "    if(combination[3] != 0.0):\n",
    "        model.add(Dropout(combination[3]))\n",
    "    model.add(Flatten())\n",
    "    for e in combination[4]:\n",
    "        model.add(Dense(e[0], activation=e[1]))\n",
    "        if(e[2] != 0.0):\n",
    "            model.add(Dropout(e[2]))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss=combination[5], optimizer=\"adam\", metrics=['acc'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train, epochs=combination[6], verbose=0)\n",
    "    result = model.evaluate(x_validate, y_validate)\n",
    "    results.append([combination, dict(zip(model.metrics_names, result))])\n",
    "    index += 1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50dec79-d62e-4bdb-8cd1-33d946e263c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'acc'\n",
    "values = []\n",
    "\n",
    "\n",
    "for i in range(len(results)):\n",
    "    values.append((results[i][0],results[i][1][metric]))\n",
    "                  \n",
    "values.sort(key=lambda tup: tup[1], reverse = True)\n",
    "\n",
    "print('Best Hyperparameter Configurations')\n",
    "for v in values:\n",
    "    print(v[0], v[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2ffaf-6969-4a47-b29b-81b15659b691",
   "metadata": {},
   "source": [
    "# Grid search target sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d09f39-dba2-48b7-b829-bc13d25736bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_1_Dropout = [0.5,0.2]\n",
    "filters = [64, 32]\n",
    "kernel_size = [5,3]\n",
    "activation_conv = ['relu']\n",
    "hidden_layers = [[(32,'relu',0.0),(16,'relu', 0.0)],[(32,'relu',0.1),(16,'relu', 0.1)],  [(24,'relu', 0.0)], [(24,'relu', 0.1)] ]\n",
    "loss = ['mse']\n",
    "epochs = [10, 20]\n",
    "\n",
    "\n",
    "combinations = list(itertools.product(*[filters, kernel_size, activation_conv, level_1_Dropout, hidden_layers, loss, epochs]))\n",
    "combinations\n",
    "\n",
    "\n",
    "\n",
    "validation_performance = []\n",
    "\n",
    "training_data = pd.read_csv(Config.TRAINING_DATASET_PATH)\n",
    "\n",
    "from preprocessing.pipeline import ItalianTweetsPreprocessingPipeline\n",
    "pp = ItalianTweetsPreprocessingPipeline()\n",
    "\n",
    "preprocessed_training_data = pp.apply(training_data)\n",
    "\n",
    "x = preprocessed_training_data['text']\n",
    "y = preprocessed_training_data['sarcasm']\n",
    "\n",
    "x= tokenize_frame(x, \"sostituisciTag\")\n",
    "x = np.asarray(x)\n",
    "\n",
    "tmp = list(zip(x,y))\n",
    "random.shuffle(tmp)\n",
    "x, y = zip(*tmp)\n",
    "\n",
    "\n",
    "validate_size = int(len(x)*VALIDATION_SPLIT)\n",
    "x_train, x_validate = x[:-validate_size], x[-validate_size:]\n",
    "x_train = np.asarray(x_train)\n",
    "x_validate = np.asarray(x_validate)\n",
    "y_train, y_validate = y[:-validate_size], y[-validate_size:]\n",
    "y_train = np.asarray(y_train)\n",
    "y_validate = np.asarray(y_validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68c1ca-0e75-4e6c-a4f9-3ebf4e880aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "index = 0\n",
    "print(\"numero di combinazioni da testare \" + str(len(combinations)))\n",
    "for combination in combinations:\n",
    "    print(\"index: \" + str(index) + \" Configurazione: \" + str(combination))\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Conv1D(filters=combination[0], kernel_size=combination[1], activation=combination[2], input_shape=(65,128)))\n",
    "    if(combination[3] != 0.0):\n",
    "        model.add(Dropout(combination[3]))\n",
    "    model.add(Flatten())\n",
    "    for e in combination[4]:\n",
    "        model.add(Dense(e[0], activation=e[1]))\n",
    "        if(e[2] != 0.0):\n",
    "            model.add(Dropout(e[2]))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss=combination[5], optimizer=\"adam\", metrics=['acc'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train, epochs=combination[6], verbose=0)\n",
    "    result = model.evaluate(x_validate, y_validate)\n",
    "    results.append([combination, dict(zip(model.metrics_names, result))])\n",
    "    index += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c8086e-0767-4982-8494-317ff988581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'acc'\n",
    "values = []\n",
    "\n",
    "\n",
    "for i in range(len(results)):\n",
    "    values.append((results[i][0],results[i][1][metric]))\n",
    "                  \n",
    "values.sort(key=lambda tup: tup[1], reverse = True)\n",
    "\n",
    "print('Best Hyperparameter Configurations')\n",
    "for v in values:\n",
    "    print(v[0], v[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb035b-c1f6-4a46-95a0-91b8c62502d6",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd313b8-7b0a-4f34-9a9f-631c9e5bb343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from config import Config\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39903d16-14d3-4672-93da-a84ec594e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(Config.TRAINING_DATASET_PATH)\n",
    "test_data = pd.read_csv(Config.TEST_DATASET_PATH)\n",
    "del test_data['id']\n",
    "del test_data['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ac799-e2eb-4f50-a08e-56068d76e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.pipeline import ItalianTweetsPreprocessingPipeline\n",
    "pp = ItalianTweetsPreprocessingPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571da90a-95aa-4dcf-aea7-ec56157e68a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_training_data = pp.apply(training_data)\n",
    "preprocessed_test_data = pp.apply(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc651aa-9b6d-4a65-8302-3d08c8a6658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocessed_training_data['text']\n",
    "x_test = preprocessed_test_data['text']\n",
    "y_train = preprocessed_training_data[['irony','sarcasm']]\n",
    "y_test = preprocessed_test_data[['irony','sarcasm']]\n",
    "va bene labuonascuola, ma noi attuali studenti di sfplm<num> bis non potremo diventare maestri prima del <num> ..! :-( <men> <men>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac4916-07fa-4118-becb-c481e04f9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv1D, Dense, Dropout, Flatten\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from preprocessing.tokenizationWordVect import tokenize_frame\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "VALIDATION_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4708bc-bbf0-4db7-b2d2-06452536236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "seed_value= 450\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172c66c-a84e-4177-a022-5009b46c6a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_conv(x, y, combination):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Conv1D(filters=combination[0], kernel_size=combination[1], activation=combination[2], input_shape=(65,128)))\n",
    "    if(combination[3] != 0.0):\n",
    "        model.add(Dropout(combination[3]))\n",
    "    model.add(Flatten())\n",
    "    for e in combination[4]:\n",
    "        model.add(Dense(e[0], activation=e[1]))\n",
    "        if(e[2] != 0.0):\n",
    "            model.add(Dropout(e[2]))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss=combination[5], optimizer=\"adam\", metrics=['acc'])\n",
    "    \n",
    "    history = model.fit(x, y, epochs=combination[6], validation_split = VALIDATION_SIZE)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddbb29f-ef57-42cb-977f-563b6bee88b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_conv = tokenize_frame(x_train, \"sostituisciTag\")\n",
    "x_train_conv = np.asarray(x_train_conv)\n",
    "\n",
    "x_test_conv = tokenize_frame(x_test, \"sostituisciTag\")\n",
    "x_test_conv = np.asarray(x_test_conv)\n",
    "\n",
    "hyperparameters_irony = [64, 5, 'relu', 0.5, [(24, 'relu', 0.1)], 'mse', 10]\n",
    "model_irony = model_conv(x_train_conv, y_train['irony'], hyperparameters_irony)\n",
    "\n",
    "hyperparameters_sarcasm = [32, 3, 'relu', 0.5, [(24, 'relu', 0.0)], 'mse', 10]\n",
    "model_sarcasm = model_conv(x_train_conv, y_train['sarcasm'], hyperparameters_sarcasm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c54107-11b7-4151-a739-f897b00184e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_metrics import model_test\n",
    "from custom_metrics import computePerformanceTaskB_2model\n",
    "\n",
    "\n",
    "print(\"F1 Average Task A\")\n",
    "print(model_test(model_irony, x_test_conv, y_test['irony']))\n",
    "print(\"F1 Average Task B\")\n",
    "print(computePerformanceTaskB_2model(model_irony, model_sarcasm, x_test_conv, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
