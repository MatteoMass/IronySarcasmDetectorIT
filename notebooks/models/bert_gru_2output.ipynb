{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61AAaBGJRKnl",
    "outputId": "2caa8c96-5693-44f8-c2ab-f94f65cb38ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'IronySarcasmDetectorIT'...\n",
      "remote: Enumerating objects: 301, done.\u001b[K\n",
      "remote: Counting objects: 100% (301/301), done.\u001b[K\n",
      "remote: Compressing objects: 100% (215/215), done.\u001b[K\n",
      "remote: Total 301 (delta 159), reused 169 (delta 74), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (301/301), 1.14 MiB | 9.87 MiB/s, done.\n",
      "Resolving deltas: 100% (159/159), done.\n",
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/gerzin/IronySarcasmDetectorIT.git\n",
    "!cd /content/IronySarcasmDetectorIT\n",
    "!git pull\n",
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ALdmdFrT9QBI",
    "outputId": "ec8456b5-e788-4947-ac75-ca4b88342ca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BkNRgIDXv9t"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/IronySarcasmDetectorIT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQUUFi4aYZ1X",
    "outputId": "66305f45-e13c-4ff2-d53c-ef4a2efc7b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "device_name = tf.test.gpu_device_name()\n",
    "print(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K18APbUaYDP1"
   },
   "source": [
    "<b>DEFINE MODELS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TyXICe8vZGfl"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install emoji\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "py0966NrYFcS"
   },
   "outputs": [],
   "source": [
    "from preprocessing.pipeline import ItalianTweetsPreprocessingPipeline\n",
    "pre_pipeline = ItalianTweetsPreprocessingPipeline(to_lowercase=False)\n",
    "df = pd.read_csv(\"/content/IronySarcasmDetectorIT/datasets/training_ironita2018.csv\")\n",
    "#pre-processing the data\n",
    "df = pre_pipeline.apply(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EUvNoK-Zj9d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmEijAJjZCRO"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "class ModelsConfig:\n",
    "    SEQUENCE_LENGTH = 50\n",
    "    BERT_ITA_XXL_CASED = \"dbmdz/bert-base-italian-xxl-cased\"\n",
    "    BERT_TOKENIZER_LENGTH = 80\n",
    "    BERT_MODEL_NAME = \"bertlstm.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PUh_9zWYTor"
   },
   "outputs": [],
   "source": [
    "from transformers import TFBertModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_bert_tokenizer(model_url=ModelsConfig.BERT_ITA_XXL_CASED, tok_len=ModelsConfig.BERT_TOKENIZER_LENGTH):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_url, add_special_tokens=True, max_length=tok_len,\n",
    "                                              pad_to_max_length=True)\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "def tokenize(sentences, tokenizer):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=128, pad_to_max_length=True,\n",
    "                                       return_attention_mask=True, return_token_type_ids=True, truncation=True)\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        input_masks.append(inputs['attention_mask'])\n",
    "        input_segments.append(inputs['token_type_ids'])\n",
    "\n",
    "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments,\n",
    "                                                                                                    dtype='int32')\n",
    "\n",
    "\n",
    "def get_bert_gru_classifier(hidden_layers, model_url=ModelsConfig.BERT_ITA_XXL_CASED):\n",
    "    with tf.device(device_name):\n",
    "      bert = TFBertModel.from_pretrained(model_url)\n",
    "\n",
    "      input_ids_in = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
    "      input_masks_in = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n",
    "\n",
    "      embedding_layer = bert(input_ids_in, attention_mask=input_masks_in)[0]\n",
    "      \n",
    "      first = True\n",
    "      for layer in hidden_layers:\n",
    "        if first:\n",
    "           X =  tf.keras.layers.GRU(layer[0], return_sequences=layer[1])(embedding_layer)\n",
    "           first = False\n",
    "        else: \n",
    "          X =  tf.keras.layers.GRU(layer[0], return_sequences=layer[1])(X)\n",
    "        if layer[2] != 0.0:\n",
    "           X = tf.keras.layers.Dropout(layer[2])(X)\n",
    "      \n",
    "      X = tf.keras.layers.Dense(2, activation = 'sigmoid')(X)\n",
    "\n",
    "      model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs=X)\n",
    "\n",
    "      for layer in model.layers[:3]:\n",
    "          layer.trainable = False\n",
    "\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141,
     "referenced_widgets": [
      "78e75e4379f24c80901500ea6031ef7f",
      "48e565edd85948e8ae95b156fd7b7e2e",
      "3a420e038f094350a70febdec9a5e359",
      "187778b98c2f481a98b968b4ee4ae62a",
      "2b85d6c444884de4ac5e9ae101a04a71",
      "cfac6263df634a16a5185f61b1311204",
      "11341de5685445ecb505c6eb10878b2c",
      "4af7beb3b2d14a51a89b5d4a33b47493",
      "e93837562fa5497ebe51e9c988dcae1a",
      "7ed5b729b6f842e8b0028809df4417e4",
      "06f63232e81d4a29bffcf2b89cfb7cb7",
      "cdb2c0ee398f43629721ccddb6cca604",
      "d3a7d5aba95445ccb36b0d6a46fcf152"
     ]
    },
    "id": "mz4SZYfzMGPG",
    "outputId": "8515891c-8851-4fb3-ef7a-1d17240b4541"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e75e4379f24c80901500ea6031ef7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb2c0ee398f43629721ccddb6cca604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a7d5aba95445ccb36b0d6a46fcf152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/230k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = get_bert_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZuuTArb4pGBb"
   },
   "source": [
    "<b>GRID SEARCH</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCwZiVwlpFfe",
    "outputId": "480fbf1a-7a64-44bf-bfbe-ccac5f40b00a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "df_gridSearch = shuffle(df)\n",
    "validation_size = int(len(df)*VALIDATION_SPLIT)\n",
    "x_train_gs = df_gridSearch['text'][validation_size:]\n",
    "y_train_gs = df_gridSearch[['irony','sarcasm']][validation_size:]\n",
    "x_vali_gs = df_gridSearch['text'][:validation_size]\n",
    "y_vali_gs = df_gridSearch[['irony','sarcasm']][:validation_size]\n",
    "\n",
    "x_train_gs = tokenize(x_train_gs, tokenizer)[:-1]\n",
    "x_vali_gs = tokenize(x_vali_gs, tokenizer)[:-1]\n",
    "\n",
    "hidden_layers = [\n",
    "                 [(128, True, 0.5), (64, True, 0.2), (16, False, 0.0)],\n",
    "                 [(128, True, 0.5), (32, False, 0.2)],\n",
    "                 [(128, True, 0.5), (16, False, 0.2)],\n",
    "                 [(128, True, 0.5), (32, False, 0.0)],\n",
    "                 [(128, False, 0.0)],\n",
    "                 [(128, False, 0.2)],\n",
    "                 [(64, False, 0.0)],\n",
    "                 [(32, False, 0.0)]]\n",
    "]\n",
    "\n",
    "loss = ['binary_crossentropy','categorical_crossentropy']\n",
    "epochs = [10]\n",
    "\n",
    "combinations = list(itertools.product(*[hidden_layers, loss, epochs]))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRDbXZo2q6AI"
   },
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n",
    "\n",
    "validation_performance = []\n",
    "index = 0\n",
    "for combination in combinations:\n",
    "  print(index)\n",
    "  model = get_bert_gru_classifier(hidden_layers = combination[0])\n",
    "  model.compile(loss=combination[1], optimizer='adam', metrics =['acc'])\n",
    "\n",
    "  model.fit(x = (x_train_gs[0], x_train_gs[1]), y = np.asarray(y_train_gs), epochs=combination[2], verbose = 0, callbacks=[early_stopping_cb])\n",
    "  result = model.evaluate(x = (x_vali_gs[0], x_vali_gs[1]), y = y_vali_gs)\n",
    "  performance = [combination, dict(zip(model.metrics_names, result))] \n",
    "  print(performance)\n",
    "  validation_performance.append(performance)\n",
    "  index +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoM_sfPotuo2"
   },
   "outputs": [],
   "source": [
    "#RISULTATI GREED SEARCH\n",
    "validation_performance = [\n",
    "                   [([(128, True, 0.5), (64, True, 0.2), (16, False, 0.0)], 'binary_crossentropy', 10), {'loss': 0.4383414936065674, 'acc': 1.0}],\n",
    "                   [([(128, True, 0.5), (64, True, 0.2), (16, False, 0.0)], 'categorical_crossentropy', 10), {'loss': 0.43652093410491943, 'acc': 1.0}],\n",
    "                   [([(128, True, 0.5), (32, False, 0.2)], 'binary_crossentropy', 10), {'loss': 0.5214934945106506, 'acc': 0.9471032619476318}],\n",
    "                   [([(128, True, 0.5), (32, False, 0.2)], 'categorical_crossentropy', 10), {'loss': 0.4481615126132965, 'acc': 0.8287153840065002}],\n",
    "                   [([(128, True, 0.5), (16, False, 0.2)], 'binary_crossentropy', 10), {'loss': 0.5187110304832458, 'acc': 0.9748110771179199}],\n",
    "                   [([(128, True, 0.5), (16, False, 0.2)], 'categorical_crossentropy', 10), {'loss': 0.4440704584121704, 'acc': 0.997481107711792}],\n",
    "                   [([(128, True, 0.5), (32, False, 0.0)], 'binary_crossentropy', 10), {'loss': 0.5266370177268982, 'acc': 0.9622166156768799}],\n",
    "                   [([(128, True, 0.5), (32, False, 0.0)], 'categorical_crossentropy', 10), {'loss': 0.4356771409511566, 'acc': 1.0}],\n",
    "                   [([(128, False, 0.0)], 'binary_crossentropy', 10), {'loss': 0.6273298859596252, 'acc': 0.992443323135376}],\n",
    "                   [([(128, False, 0.0)], 'categorical_crossentropy', 10), {'loss': 0.41610702872276306, 'acc': 0.982367753982544}],\n",
    "                   [([(128, False, 0.2)], 'binary_crossentropy', 10), {'loss': 0.6418942809104919, 'acc': 0.8942065238952637}],\n",
    "                   [([(128, False, 0.2)], 'categorical_crossentropy', 10), {'loss': 0.4152664542198181, 'acc': 0.997481107711792}],\n",
    "                   [([(64, False, 0.0)], 'binary_crossentropy', 10), {'loss': 0.5600593090057373, 'acc': 0.9773299694061279}],\n",
    "                   [([(64, False, 0.0)], 'categorical_crossentropy', 10), {'loss': 0.42633721232414246, 'acc': 0.992443323135376}],\n",
    "                   [([(32, False, 0.0)], 'binary_crossentropy', 10), {'loss': 0.5144029259681702, 'acc': 0.9219143390655518}],\n",
    "                   [([(32, False, 0.0)], 'categorical_crossentropy', 10), {'loss': 0.44485291838645935, 'acc': 0.9596977233886719}]\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Ny132met7v9",
    "outputId": "691f5f0a-ac16-49d9-c208-f26603a904fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters\n",
      "([(128, True, 0.5), (64, True, 0.2), (16, False, 0.0)], 'binary_crossentropy', 10) 1.0\n",
      "([(128, True, 0.5), (64, True, 0.2), (16, False, 0.0)], 'categorical_crossentropy', 10) 1.0\n",
      "([(128, True, 0.5), (32, False, 0.0)], 'categorical_crossentropy', 10) 1.0\n",
      "([(128, True, 0.5), (16, False, 0.2)], 'categorical_crossentropy', 10) 0.997481107711792\n",
      "([(128, False, 0.2)], 'categorical_crossentropy', 10) 0.997481107711792\n",
      "([(128, False, 0.0)], 'binary_crossentropy', 10) 0.992443323135376\n",
      "([(64, False, 0.0)], 'categorical_crossentropy', 10) 0.992443323135376\n",
      "([(128, False, 0.0)], 'categorical_crossentropy', 10) 0.982367753982544\n",
      "([(64, False, 0.0)], 'binary_crossentropy', 10) 0.9773299694061279\n",
      "([(128, True, 0.5), (16, False, 0.2)], 'binary_crossentropy', 10) 0.9748110771179199\n",
      "([(128, True, 0.5), (32, False, 0.0)], 'binary_crossentropy', 10) 0.9622166156768799\n",
      "([(32, False, 0.0)], 'categorical_crossentropy', 10) 0.9596977233886719\n",
      "([(128, True, 0.5), (32, False, 0.2)], 'binary_crossentropy', 10) 0.9471032619476318\n",
      "([(32, False, 0.0)], 'binary_crossentropy', 10) 0.9219143390655518\n",
      "([(128, False, 0.2)], 'binary_crossentropy', 10) 0.8942065238952637\n",
      "([(128, True, 0.5), (32, False, 0.2)], 'categorical_crossentropy', 10) 0.8287153840065002\n"
     ]
    }
   ],
   "source": [
    "metric = 'acc'\n",
    "values = []\n",
    "\n",
    "for i in range(len(validation_performance)):\n",
    "  values.append((validation_performance[i][0], validation_performance[i][1][metric]))\n",
    "\n",
    "values.sort(key=lambda tup: tup[1], reverse = True)\n",
    "\n",
    "\n",
    "print('Best Hyperparameters')\n",
    "for v in values:\n",
    "  print(v[0], v[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2R9UeJOLS79Q"
   },
   "source": [
    "<b>FITTING THE BEST MODEL</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTmgQFKwhTMk"
   },
   "outputs": [],
   "source": [
    "# Seed value\n",
    "seed_value= 450\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "# for later versions: \n",
    "# tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233,
     "referenced_widgets": [
      "89209d1230f34c8f9402fc4783321ca5"
     ]
    },
    "id": "d4h2jgSQTB3x",
    "outputId": "5119a869-42ba-433d-8c12-a6a7dd50d76d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89209d1230f34c8f9402fc4783321ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/520M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dbmdz/bert-base-italian-xxl-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-italian-xxl-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7121154496281271, 0.5357410280490237]\n"
     ]
    }
   ],
   "source": [
    "from custom_metrics import computePerformanceTaskB_2output\n",
    "df_train = pd.read_csv(\"/content/IronySarcasmDetectorIT/datasets/training_ironita2018.csv\")\n",
    "#pre-processing the data\n",
    "df_train = pre_pipeline.apply(df_train)\n",
    "\n",
    "df_test = pd.read_csv(\"/content/IronySarcasmDetectorIT/datasets/test_gold_ironita2018.csv\")\n",
    "df_test = pre_pipeline.apply(df_test)\n",
    "\n",
    "x_train = df_train['text']\n",
    "y_train = df_train[['irony','sarcasm']]\n",
    "\n",
    "x_test = df_test['text']\n",
    "y_test = df_test[['irony','sarcasm']]\n",
    "x_test = tokenize(x_test, tokenizer)[:-1]\n",
    "x_train = tokenize(x_train, tokenizer)[:-1]\n",
    "\n",
    "best_combination = ([(128, True, 0.5), (64, True, 0.2), (16, False, 0.0)], 'binary_crossentropy', 10)\n",
    "model = get_bert_gru_classifier(hidden_layers = best_combination[0])\n",
    "model.compile(loss=best_combination[1], optimizer='adam', metrics =['acc'])\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n",
    "\n",
    "model.fit(x = (x_train[0], x_train[1]), y = np.asarray(y_train), epochs=best_combination[2], verbose = 0, callbacks=[early_stopping_cb])\n",
    "\n",
    "\n",
    "print(computePerformanceTaskB_2output(model, x_test, y_test, y_test['irony']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6TvsNyILPWu",
    "outputId": "157905ea-c690-4990-c787-03aa83d7311b"
   },
   "source": [
    "<b>SAVE MODEL</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/content/GRU/model\", save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "huC5aB5T9gMn",
    "outputId": "c0b156b2-7069-4dd7-9781-d55cc2b5e64f"
   },
   "outputs": [],
   "source": [
    "!zip -r \"/content/model.zip\" \"/content/GRU/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.download(\"/content/model.zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2outGRU_gs_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06f63232e81d4a29bffcf2b89cfb7cb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11341de5685445ecb505c6eb10878b2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "187778b98c2f481a98b968b4ee4ae62a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e93837562fa5497ebe51e9c988dcae1a",
      "max": 59,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4af7beb3b2d14a51a89b5d4a33b47493",
      "value": 59
     }
    },
    "2b85d6c444884de4ac5e9ae101a04a71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06f63232e81d4a29bffcf2b89cfb7cb7",
      "placeholder": "​",
      "style": "IPY_MODEL_7ed5b729b6f842e8b0028809df4417e4",
      "value": " 59.0/59.0 [00:00&lt;00:00, 1.51kB/s]"
     }
    },
    "3a420e038f094350a70febdec9a5e359": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11341de5685445ecb505c6eb10878b2c",
      "placeholder": "​",
      "style": "IPY_MODEL_cfac6263df634a16a5185f61b1311204",
      "value": "Downloading: 100%"
     }
    },
    "48e565edd85948e8ae95b156fd7b7e2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4af7beb3b2d14a51a89b5d4a33b47493": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "78e75e4379f24c80901500ea6031ef7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a420e038f094350a70febdec9a5e359",
       "IPY_MODEL_187778b98c2f481a98b968b4ee4ae62a",
       "IPY_MODEL_2b85d6c444884de4ac5e9ae101a04a71"
      ],
      "layout": "IPY_MODEL_48e565edd85948e8ae95b156fd7b7e2e"
     }
    },
    "7ed5b729b6f842e8b0028809df4417e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfac6263df634a16a5185f61b1311204": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e93837562fa5497ebe51e9c988dcae1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
